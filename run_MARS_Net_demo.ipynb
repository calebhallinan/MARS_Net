{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_MARS_Net_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleelab-bch/MARS-Net/blob/master/run_MARS_Net_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV-XxsfVboh2"
      },
      "source": [
        "# GPU Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-FDqnGqbscX"
      },
      "source": [
        "Verify that GPU is selected. <br>\n",
        "You can select GPU by\n",
        "Edit -> Notebook settings -> Set Hardware Accelerator to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfKANu3UabET",
        "outputId": "b6c2b429-cbd9-44c5-c682-acea2af90de7"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Sun Apr 11 04:15:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tde_AepcQH2"
      },
      "source": [
        "# Example models and images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLRKH33Yc2Dd"
      },
      "source": [
        "Upload Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "-lT-Jy6lEjk1",
        "outputId": "5b157f1d-c14b-4655-8589-c5da9b35f18b"
      },
      "source": [
        "url = 'https://github.com/kleelab-bch/MARS-Net/blob/master/assets/040119_PtK1_S01_01_phase_ROI2/img_all/040119_PtK1_S01_01_phase_ROI2_1_001.png?raw=true'\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_io.BytesIO object at 0x7fce7de57b90>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3a386eef1314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 2896\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2897\u001b[0m     )\n\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7fce7de57b90>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN8wQ5h9EQzB"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHTkGX5gP967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f994e31b-08b3-46f1-a26c-c5108bab8005"
      },
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import os.path\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0HWXxDSEID5"
      },
      "source": [
        "\n",
        "def UNet(img_rows, img_cols, crop_margin, right_crop, bottom_crop, weights_path):\n",
        "    inputs = Input((3, img_rows, img_cols))\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "    if bottom_crop == 0:\n",
        "        conv10 = Cropping2D(cropping=((crop_margin, crop_margin),(crop_margin, crop_margin)))(conv10) # ((top_crop, bottom_crop), (left_crop, right_crop)) for training\n",
        "    else:\n",
        "        conv10 = Cropping2D(cropping=((0, bottom_crop),(0, right_crop)))(conv10)  # remove reflected portion from the image for prediction\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    weights_path = get_file(\n",
        "        'vgg19_weights.h5',\n",
        "        'https://github.com/kleelab-bch/MARS-Net/raw/master/models/results/model_round1_specialist_unet/model_frame2_D_repeat0.hdf5')\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fwYx6wvEGTk"
      },
      "source": [
        "\n",
        "def VGG19_dropout(img_rows, img_cols, crop_margin, right_crop, bottom_crop):\n",
        "    inputs = Input(shape=[3, img_rows, img_cols])\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
        "    block1_conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(block1_conv2)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    block2_conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(block2_conv2)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    block3_conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(block3_conv4)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    block4_conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(block4_conv4)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    block5_conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
        "\n",
        "\n",
        "    # upsampling model\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(block5_conv4), block4_conv4], axis=1)\n",
        "    up6 = Dropout(0.5)(up6)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), block3_conv4], axis=1)\n",
        "    up7 = Dropout(0.5)(up7)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), block2_conv2], axis=1)\n",
        "    up8 = Dropout(0.5)(up8)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), block1_conv2], axis=1)\n",
        "    up9 = Dropout(0.5)(up9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "    if bottom_crop == 0:\n",
        "        conv10 = Cropping2D(cropping=((crop_margin, crop_margin), (crop_margin, crop_margin)))(conv10)  # ((top_crop, bottom_crop), (left_crop, right_crop)) for training\n",
        "    else:\n",
        "        conv10 = Cropping2D(cropping=((0, bottom_crop), (0, right_crop)))(conv10)  # remove reflected portion from the image for prediction\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    # Load weights.\n",
        "    weights_path = get_file(\n",
        "        'vgg19_weights.h5',\n",
        "        'https://github.com/kleelab-bch/MARS-Net/raw/master/models/results/model_round1_generalist_VGG19_dropout/model_frame2_D_repeat0.hdf5')\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_msIJbeMEa6B"
      },
      "source": [
        "# Run trained model to segment phase contrast live cell movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAvGiGijGnfY"
      },
      "source": [
        "## Code for data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdAyVCMDF85m"
      },
      "source": [
        "def to3channel(imgs):\n",
        "    imgs_p = np.repeat(imgs, 3, axis=1)\n",
        "    imgs_p = imgs_p.astype('float32')\n",
        "\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def preprocess_output(imgs):\n",
        "    imgs_p = imgs.astype('float32')\n",
        "    imgs_p /= 255.  # scale masks to [0, 1]\n",
        "\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def preprocess_input(imgs, std=None, mean=None):\n",
        "    imgs_p = to3channel(imgs)\n",
        "    if std is None:\n",
        "        std = np.std(imgs_p)\n",
        "    if mean is None:\n",
        "        mean = np.mean(imgs_p)\n",
        "\n",
        "    imgs_p -= mean\n",
        "    imgs_p /= std\n",
        "\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def normalize_input(imgs):\n",
        "    imgs_p = to3channel(imgs)\n",
        "    imgs_p /= 255.  # scale image to [0, 1]\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def square(list):\n",
        "    return [i ** 2 for i in list]\n",
        "\n",
        "\n",
        "def get_rest_indices_from_all(all_indices, chosen_index):\n",
        "    '''\n",
        "    given a list of indices, and one chosen dataset index,\n",
        "    get indices other than the chosen dataset index\n",
        "    '''\n",
        "    rest_indices = set(all_indices) - set([chosen_index])\n",
        "    return list(rest_indices)\n",
        "\n",
        "\n",
        "def loop_aggregate_std_mean(constants):\n",
        "    for dataset_index in range(0, len(constants.dataset), 1):\n",
        "        for frame in constants.frame_list:\n",
        "            aggregate_std_mean(constants, dataset_index, frame)\n",
        "\n",
        "\n",
        "def aggregate_std_mean_except(constants, dataset_index, frame, crop_path):\n",
        "    print(constants.model_names[dataset_index], end=' ')\n",
        "    print(frame)\n",
        "    frame_mean_list = []\n",
        "    frame_std_list = []\n",
        "    rest_indices = get_rest_indices_from_all(range(len(constants.dataset)), dataset_index)\n",
        "    for rest_index in rest_indices:\n",
        "        std_mean = np.load(crop_path + constants.dataset[rest_index] + '_' + str(frame) + '_std_mean.npz')\n",
        "        mean_value = std_mean['arr_0'].tolist()\n",
        "        std_value = std_mean['arr_1'].tolist()\n",
        "\n",
        "        frame_mean_list.append(mean_value)\n",
        "        frame_std_list.append(std_value)\n",
        "        print(constants.dataset[rest_index], mean_value, std_value)\n",
        "    frame_mean_value = statistics.mean(frame_mean_list)\n",
        "    frame_std_value = math.sqrt(statistics.mean(square(frame_std_list)))\n",
        "    return frame_std_value, frame_mean_value\n",
        "\n",
        "\n",
        "def aggregate_std_mean(dataset_names, excluded_dataset_name, frame, repeat_index, crop_path):\n",
        "    # for self training five fold validation,\n",
        "    # get average of std and mean from four movies to preprocess the test set images.\n",
        "    print('aggregate_std_mean:' + str(frame))\n",
        "    frame_mean_list = []\n",
        "    frame_std_list = []\n",
        "\n",
        "    for dataset_index in range(len(dataset_names)):\n",
        "        if dataset_names[dataset_index] != excluded_dataset_name:\n",
        "            save_suffix = '{}_frame{}_repeat{}'.format(dataset_names[dataset_index], str(frame), str(repeat_index))\n",
        "            std_mean = np.load(crop_path + save_suffix + '_std_mean.npz')\n",
        "            mean_value = std_mean['arr_0'].tolist()\n",
        "            std_value = std_mean['arr_1'].tolist()\n",
        "\n",
        "            frame_mean_list.append(mean_value)\n",
        "            frame_std_list.append(std_value)\n",
        "            print(dataset_names[dataset_index], mean_value, std_value)\n",
        "    frame_mean_value = statistics.mean(frame_mean_list)\n",
        "    frame_std_value = math.sqrt(statistics.mean(square(frame_std_list)))\n",
        "    return frame_std_value, frame_mean_value\n",
        "\n",
        "\n",
        "def get_std_mean_from_images(all_img_path, img_format):\n",
        "    img_list = glob.glob(all_img_path + '*' + img_format)\n",
        "\n",
        "    if len(img_list) == 0:  # skip this dataset\n",
        "        print('img list is empty')\n",
        "        exit()\n",
        "\n",
        "    img = cv2.imread(img_list[0], cv2.IMREAD_GRAYSCALE)\n",
        "    img_r, img_c = img.shape\n",
        "    total_number = len(img_list)\n",
        "    imgs = np.ndarray((total_number, img_r, img_c), dtype=np.uint8)\n",
        "    for i in range(len(img_list)):\n",
        "        img_path = img_list[i]\n",
        "        img_name = img_path[len(all_img_path):]\n",
        "        imgs[i] = cv2.imread(all_img_path + img_name, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    avg = np.mean(imgs)\n",
        "    std = np.std(imgs)\n",
        "    return std, avg\n",
        "\n",
        "class DataGenerator:\n",
        "    def __init__(self, img_path, n_frames_train, input_size, output_size, strategy_type, img_format = '.png'):\n",
        "        self.n_frames_train = n_frames_train\n",
        "        self.img_path = img_path\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.strategy_type = strategy_type\n",
        "        self.img_format = img_format\n",
        "        self.row, self.col = self.get_img_size()\n",
        "\n",
        "    def get_expanded_whole_frames(self):\n",
        "        img_list = self.find_namespace()\n",
        "        imgs, image_rows, image_cols = self.get_expanded_images(self.img_path, img_list)\n",
        "\n",
        "        # ------------------- pre-processing images -------------------\n",
        "        # std and mean from test set images\n",
        "        std_value, mean_value = get_std_mean_from_images(self.img_path, img_format=self.img_format)\n",
        "        print(mean_value, std_value)\n",
        "\n",
        "        # std and mean from training set images, Don't use it because it yields worse prediction results\n",
        "        # crop_path, _ = constants.get_crop_path(model_name, dataset_name, str(frame), str(0), str(repeat_index))\n",
        "        # std_value, mean_value = aggregate_std_mean(constants.dataset_names, dataset_name, frame, repeat_index, crop_path)\n",
        "\n",
        "        imgs = imgs[:, np.newaxis, :, :]\n",
        "        if 'no_preprocessing' in str(self.strategy_type):\n",
        "            imgs = to3channel(imgs)\n",
        "        elif 'normalize_clip' in str(self.strategy_type):\n",
        "            imgs = normalize_clip_input(imgs)\n",
        "        elif 'normalize' in str(self.strategy_type):\n",
        "            imgs = normalize_input(imgs)\n",
        "        elif 'heq' in str(self.strategy_type):\n",
        "            imgs = heq_norm_input(imgs)\n",
        "        else:\n",
        "            imgs = preprocess_input(imgs, std_value, mean_value)\n",
        "        \n",
        "        return imgs, img_list, image_cols, image_rows, self.col, self.row\n",
        "\n",
        "    def find_namespace(self):\n",
        "        img_list = []\n",
        "        img_path = self.img_path\n",
        "        \n",
        "        img_filename_list = os.listdir(img_path)\n",
        "        for img_filename in img_filename_list:\n",
        "            if os.path.isfile(img_path + img_filename) and img_filename.endswith(self.img_format):\n",
        "                img_list.append(img_filename)\n",
        "        return img_list\n",
        "\n",
        "    def get_img_size(self):\n",
        "        img_path = self.img_path\n",
        "        img_list = self.find_namespace()\n",
        "        for file in img_list:\n",
        "            if os.path.isfile(img_path + file) and file.endswith(self.img_format):\n",
        "                return cv2.imread(img_path + file , cv2.IMREAD_GRAYSCALE).shape\n",
        "        print(\"ERROR: get_img_size\")\n",
        "        return -1, -1\n",
        "\n",
        "    def get_expanded_images(self,img_path, namelist, ratio = 64.0):\n",
        "        # expand test set images because our model only takes the image of size in ratio of 64\n",
        "        total_number = len(namelist)\n",
        "        imgs_row_exp = int(np.ceil(np.divide(self.row, ratio) ) * ratio)\n",
        "        imgs_col_exp = int(np.ceil(np.divide(self.col, ratio) ) * ratio)\n",
        "\n",
        "        # crop images that are not expanded enough\n",
        "        # this is necessary to prevent boundary effect\n",
        "        if (imgs_row_exp - self.row) < ratio:\n",
        "            imgs_row_exp = imgs_row_exp + int(ratio)\n",
        "            print('imgs_row_exp', imgs_row_exp)\n",
        "\n",
        "        if (imgs_col_exp - self.col) < ratio:\n",
        "            imgs_col_exp = imgs_col_exp + int(ratio)\n",
        "            print('imgs_col_exp', imgs_col_exp)\n",
        "\n",
        "        imgs = np.ndarray((total_number, int(imgs_row_exp), int(imgs_col_exp)), dtype=np.uint8) \n",
        "        i = 0\n",
        "        for name in namelist:\n",
        "            img = cv2.resize( cv2.imread(img_path + name, cv2.IMREAD_GRAYSCALE),(int(self.col), int(self.row)), interpolation = cv2.INTER_CUBIC)\n",
        "            imgs[i] = cv2.copyMakeBorder(img, 0, imgs_row_exp - self.row, 0, imgs_col_exp - self.col, cv2.BORDER_REFLECT)\n",
        "            i += 1\n",
        "        return imgs, imgs_row_exp, imgs_col_exp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvZqB1fGHAiG"
      },
      "source": [
        "## Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJkeH40E6Xy"
      },
      "source": [
        "K.set_image_data_format('channels_first')\n",
        "root_prediciton_path = \"results/predict_wholeframe_round1_demo/\"\n",
        "\n",
        "frame = 2\n",
        "model_index = 1\n",
        "model_name = 'D'\n",
        "dataset_folder = './assets/'\n",
        "dataset_name = '040119_PtK1_S01_01_phase_ROI2'\n",
        "img_folder = '/img_all/'\n",
        "img_format = '.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Ret3XyJNH4"
      },
      "source": [
        "VGG19_dropout(img_rows, img_cols, crop_margin, right_crop, bottom_crop):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1uAWqu0GukF"
      },
      "source": [
        "## Segment the movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8g__Tg361MN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "083ace77-6f4a-4050-cb22-cef18e455ce4"
      },
      "source": [
        "img_path = 'https://github.com/kleelab-bch/MARS-Net/tree/master/assets/040119_PtK1_S01_01_phase_ROI2/img_all'\n",
        "    \n",
        "save_path = './{}/frame{}_{}/'.format(dataset_name, str(frame), model_name)\n",
        "\n",
        "# ------------------- Data loading -------------------\n",
        "strategy_type = 'VGG19_dropout'\n",
        "prediction_data_generator = DataGenerator(img_path, frame, 128, 68, strategy_type, img_format=img_format)\n",
        "imgs_val, namelist, image_cols, image_rows, orig_cols, orig_rows = prediction_data_generator.get_expanded_whole_frames()\n",
        "\n",
        "print('img size:', image_rows, image_cols)\n",
        "print('orig img size:', orig_rows, orig_cols)\n",
        "print('imgs_val: ', imgs_val.dtype, imgs_val.shape)\n",
        "\n",
        "# ------------------- Load trained Model -------------------\n",
        "\n",
        "VGG19_dropout_model = VGG19_dropout(image_rows, image_cols, 0, image_cols-orig_cols, image_rows-orig_rows)\n",
        "UNet_model = UNet(image_rows, image_cols, 0, image_cols-orig_cols, image_rows-orig_rows)\n",
        "\n",
        "print('model layers: ', len(model.layers))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c6938a912067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ------------------- Data loading -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstrategy_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'VGG19_dropout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprediction_data_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m68\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimgs_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expanded_whole_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fdb979ed7a24>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, n_frames_train, input_size, output_size, strategy_type, img_format)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expanded_whole_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fdb979ed7a24>\u001b[0m in \u001b[0;36mget_img_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_img_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mimg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fdb979ed7a24>\u001b[0m in \u001b[0;36mfind_namespace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mimg_filename_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_filename_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './assets/040119_PtK1_S01_01_phase_ROI2/img_all/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klz8MxCJE9pY"
      },
      "source": [
        "# ------------------- predict segmented images and save them -------------------\n",
        "\n",
        "segmented_output = model.predict(imgs_val, batch_size = 1, verbose = 1)\n",
        "segmented_output = 255 * segmented_output  # 0=black color and 255=white color\n",
        "\n",
        "for f in range(len(namelist)):\n",
        "    out = segmented_output[f, 0, :, :]\n",
        "    cv2.imwrite(save_path + namelist[f], out)\n",
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}